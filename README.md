# Image-steganography-CNN
# (i)Preprocessing module, (ii)Embedding network, (iii) Extraction network and (iv) Customized loss function.

Preprocessing module: In this methodology, the features are extracted directly from them other than processing the raw form of the cover and the hidden image. This is done to reduce the burden on the embedded network and only extracting the significant features as the high-resolution image may contain redundant data which is of no use and to avoid consumption of storage. The input should have the format m x m x n; the representation of the three dimensions, that is width, height and depth. The size of the cover image is secured to be 256 x 256, but the input secret image could be of any size and the processing module would resize it to the size of the cover image, which is 256 x 256. One input layer, three convolutional layers, and an increasing number of filters help compensate the preprocessing module.The primary goal of the preprocessing module is the extraction of useful and significant features using convolutional layers with various filter sizes. In the beginning, edges and other lower-level local characteristics are retrieved using smaller filter sizes. To assist the model in learning more sophisticated characteristics, the filter size is raised. 8, 16, and 32 filters are utilised in total. The preprocessing programme processes both the cover picture and the hidden image simultaneously. The features that were extracted from the cover picture and the secret image are finally concatenated in a merge layer that is created.[1]
Embedding Network: This autoencoder network draws the input and brings out the feature using the encoder. The decoder part is used to re-establish the output image from the latent space. The latent space in the end of the encoder brings out the best features of both cover image and secret image concatenated.The encoder portion of the embedding network comprises 64 and 128 filters, and the decoder portion has 128, 64, 32, 16 and 8 filters. At the conclusion of the convolutional layers, ReLU activation is used to introduce linearity by providing the maximum value for positives and 0s for negatives. ReLU is utilised because it solves the vanishing gradient problem that plagues architectures with several layers, making training simpler while improving performance. ReLU is denoted by h(c) = max (0,c). After the embedding network, a convolutional layer with three filters is added to transform the 256 x 256 x 8 feature vector into an output 256 x 256 x 3 stego picture. [1]
Extraction Network: The main aim of extraction network is to extract the secret image concealed inside the stego image. There is an expanding phase and a contracting phase for this network. The amount of filter, size, stride and hyperparameters are precisely tuned according to the experimental results.The extraction network's growing encoder portion contains five convolutional layers and an increasing number of filters (8, 16, 32, 64, 128). Five convolutional layers with a decreasing number of filters (128, 64, 32, 16, 8) make up the decoder component. Each layer has a ReLU activation built into it. A convolutional layer with three filters is added after the decoder in the extraction network to create the extracted secret picture. [1]
Customized Loss Function: Unalike, conventional way of image reconstruction, image steganography must have two input images and two output images. As this is the reason, regular loss function would not help this purpose. The introduction of a tailored loss function boosts the architecture's performance. The embedding loss and the extraction loss are the two losses that need to be computed.Between the input cover picture and the output stego image created by the embedding network, the embedding loss is determined. The extraction network, on the other hand, calculates the extraction loss between the input secret picture and the extracted secret image. The sum of the embedding loss and the extraction loss is the overall loss.

